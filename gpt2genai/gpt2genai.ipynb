{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f99a37-455b-4b57-b8ca-2fbdc88749ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\kadam\\anaconda3\\lib\\site-packages (4.47.0)\n",
      "Requirement already satisfied: torch in c:\\users\\kadam\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: accelerate in c:\\users\\kadam\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: flask in c:\\users\\kadam\\anaconda3\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: flask-ngrok in c:\\users\\kadam\\anaconda3\\lib\\site-packages (0.0.25)\n",
      "Requirement already satisfied: filelock in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from flask) (3.0.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from flask) (1.6.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kadam\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "# Install Necessary Libraries\n",
    "!pip install transformers torch accelerate flask flask-ngrok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb07b85-ed13-46fe-8ce3-2ec95d56cce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pre-trained Model and Tokenizer\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "model_name = 'gpt2'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# Add a padding token\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "# Tokenize Your Data\n",
    "data = [\"Sample text\", \"Another example text\"]\n",
    "tokenized_data = tokenizer(data, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "# Add labels to the dataset (input_ids can be used as labels for language modeling)\n",
    "tokenized_data['labels'] = tokenized_data.input_ids.detach().clone()\n",
    "\n",
    "# Convert tokenized data to Dataset format\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        return item\n",
    "\n",
    "train_dataset = TextDataset(tokenized_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f0554c7-4638-4c97-b3d2-3ea4991b7fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:28, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20, training_loss=9.795569610595702, metrics={'train_runtime': 31.3761, 'train_samples_per_second': 1.275, 'train_steps_per_second': 0.637, 'total_flos': 61240320000.0, 'train_loss': 9.795569610595702, 'epoch': 20.0})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Fine-Tuning Process\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Resize token embeddings to account for new pad token\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=20,              # number of training epochs\n",
    "    per_device_train_batch_size=4,   # batch size for training\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset          # training dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79667a03-9374-476e-8525-8a787dda237c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text 1: Once upon a time the times I did not like my own job (and even if they'd been good) and as in all things that were necessary.\n",
      "If you have any more questions then please do this: We believe there was one person who would let me write about something called \"Hollow Men's Workout.\" And it worked really well for three days, because no matter how hard anyone tried to stop him from writing he got into pretty bad form so at least their body can help take\n",
      "Generated text 2: Once upon a time, with all our knowledge of the human condition that we can imagine and what it is impossible to do because in this very moment everything becomes clear. But there are those who will not believe or even understand these things.\"\n",
      "When he spoke at last night's funeral Mass one thing was made painfully evident: The Prophet Muhammad has written an unsearchable book about his life by saying some words so far removed from God himself; but as I have said before they were just more than mere\n",
      "Generated text 3: Once upon a time I had trouble with one thing. A girl's been very fond of her, and as soon she came to my door so that he saw what was happening at work it\n",
      "In this post the next week you will be your \"best friend\" but we just need an excuse for all these years where i'm afraid because no matter how far off from home they come there are only five things: 1 You know when someone is going through something on their own account then people get in\n",
      "Generated text 4: Once upon a time, for many days at least some the work will not take place in it. (S):\n",
      "If you were to be able to get all your stuff straight out of those boxes and put away there was no one who could wait more than four hours until someone else would leave with nothing but food or water on them when they are done being made from these things! I mean really make do have other people here so thank me very much ! But now that we got something finished off\n",
      "Generated text 5: Once upon a time he came to see me with an open book in hand. He said I could write the answer from his eyes only, as though there was no question at all about what is going on here; so that when it would seem strange and wonderful if they were saying \"We are not our gods but we really think ourselves\".\n",
      "\n",
      "So my father took some advice of himself which went into writing such has been seen them speak for themselves who do look back this experience out over three years\n"
     ]
    }
   ],
   "source": [
    "# Function to Generate Multiple Unique Texts\n",
    "def generate_text(prompt, num_return_sequences=5):\n",
    "    inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=100,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        do_sample=True,       # Enable sampling\n",
    "        temperature=1.0,      # Increase temperature for more diversity\n",
    "        top_k=50,             # Limits the sampling pool to top_k tokens\n",
    "        top_p=0.9,            # Use nucleus sampling; limits to tokens with top_p cumulative probability\n",
    "        repetition_penalty=1.2 # Apply a penalty to reduce repetitive output\n",
    "    )\n",
    "    generated_texts = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "    return generated_texts\n",
    "\n",
    "# Example Usage\n",
    "unique_texts = generate_text(\"Once upon a time\", num_return_sequences=5)\n",
    "for i, text in enumerate(unique_texts):\n",
    "    print(f\"Generated text {i+1}: {text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3593a072-6935-4573-a13b-97aa819966db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 199, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 85, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 789, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 495, in _make_request\n",
      "    conn.request(\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 441, in request\n",
      "    self.endheaders()\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\http\\client.py\", line 1331, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\http\\client.py\", line 1091, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\http\\client.py\", line 1035, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 279, in connect\n",
      "    self.sock = self._new_conn()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 214, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001D383806480>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 843, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D383806480>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\threading.py\", line 1433, in run\n",
      "    self.function(*self.args, **self.kwargs)\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\site-packages\\flask_ngrok.py\", line 70, in start_ngrok\n",
      "    ngrok_address = _run_ngrok()\n",
      "                    ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\site-packages\\flask_ngrok.py\", line 35, in _run_ngrok\n",
      "    tunnel_url = requests.get(localhost_url).text  # Get the tunnel information\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\site-packages\\requests\\api.py\", line 73, in get\n",
      "    return request(\"get\", url, params=params, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\site-packages\\requests\\api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kadam\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 700, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D383806480>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n"
     ]
    }
   ],
   "source": [
    "# Create a Simple Flask App\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_ngrok import run_with_ngrok\n",
    "\n",
    "app = Flask(__name__)\n",
    "run_with_ngrok(app)\n",
    "\n",
    "@app.route('/generate', methods=['POST'])\n",
    "def generate():\n",
    "    prompt = request.json['input']\n",
    "    generated_text = generate_text(prompt)\n",
    "    return jsonify({'generated_text': generated_text})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9815b98-c3df-40b0-8a80-513c350f4114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
